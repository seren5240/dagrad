{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10a05db70>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import dagrad.flex as flex\n",
    "from dagrad.utils import utils\n",
    "import numpy as np\n",
    "from dagrad.flex.prune import cam_pruning\n",
    "\n",
    "utils.set_random_seed(1)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(B, graph_thres=0.3):\n",
    "    \"\"\"Post-process estimated solution:\n",
    "        (1) Thresholding.\n",
    "        (2) Remove the edges with smallest absolute weight until a DAG\n",
    "            is obtained.\n",
    "\n",
    "    Args:\n",
    "        B (numpy.ndarray): [d, d] weighted matrix.\n",
    "        graph_thres (float): Threshold for weighted matrix. Default: 0.3.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: [d, d] weighted matrix of DAG.\n",
    "    \"\"\"\n",
    "    B = np.copy(B)\n",
    "    B[np.abs(B) <= graph_thres] = 0    # Thresholding\n",
    "    B, _ = utils.threshold_till_dag(B)\n",
    "\n",
    "    return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Struct Learn via Flex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`flex.struct_learn` is a function that requires the following 5 inputs:\n",
    "- `dataset`: A data matrix with `n x d` shape, where `n` is the number of samples and `d` is the number of variables/features.\n",
    "\n",
    "- `model`: The SEM module. We provide standard SEM implementations such as---LinearModel, LogisticModel, MLP\n",
    "\n",
    "- `constrained_solver`: An instance of a ConstrainedSolver class. We provide implementations such as `PathFollowing` and `AugmentedLagrangian`\n",
    "\n",
    "- `unconstrained_solver`: An instance of an UnconstrainedSolver class. We provide implementation for `GradientBasedSolver`\n",
    "\n",
    "- `loss_fn`: Instance of a Loss class. All available losses can be found at flex/loss.py\n",
    "\n",
    "- `dag_fn`: Instance of a DagFn class. All available DAG functions can be found at flex/dags.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate linear data\n",
    "n, d, s0, graph_type, sem_type = 1000, 20, 20, \"ER\", \"gauss\"\n",
    "linear_B_true = utils.simulate_dag(d, s0, graph_type)\n",
    "linear_dataset = utils.simulate_linear_sem(linear_B_true, n, sem_type)\n",
    "\n",
    "# Generate non-linear data\n",
    "n, d, s0, graph_type, sem_type = 1000, 5, 5, \"ER\", \"mlp\"\n",
    "nonlinear_B_true = utils.simulate_dag(d, s0, graph_type)\n",
    "nonlinear_dataset = utils.simulate_nonlinear_sem(nonlinear_B_true, n, sem_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using flex to implement NOTEARS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linear NOTEARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:37<00:00,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time: 37.8957781791687\n",
      "Results:  {'fdr': 0.0, 'tpr': 1.0, 'fpr': 0.0, 'shd': 0, 'nnz': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear model\n",
    "model = flex.LinearModel(d)\n",
    "\n",
    "# Use AML to solve the constrained problem\n",
    "cons_solver = flex.AugmentedLagrangian(\n",
    "    num_iter=10,\n",
    "    num_steps=[3e4,6e4],\n",
    "    l1_coeff=0.03,\n",
    ")\n",
    "\n",
    "# Use Adam to solve the unconstrained problem\n",
    "uncons_solver = flex.GradientBasedSolver(\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=3e-4),\n",
    ")\n",
    "\n",
    "# Use MSE loss\n",
    "loss_fn = flex.MSELoss()\n",
    "\n",
    "# Use Trace of matrix exponential as DAG function\n",
    "dag_fn = flex.Exp()\n",
    "\n",
    "# Learn the DAG\n",
    "W_est = flex.struct_learn(\n",
    "    dataset=linear_dataset,\n",
    "    model=model,\n",
    "    constrained_solver=cons_solver,\n",
    "    unconstrained_solver=uncons_solver,\n",
    "    loss_fn=loss_fn,\n",
    "    dag_fn=dag_fn,\n",
    "    w_threshold=0.3,\n",
    ")\n",
    "\n",
    "acc = utils.count_accuracy(linear_B_true, W_est != 0)\n",
    "print(\"Results: \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nonlinear NOTEARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grandag_aug_lagrangian(n, d, s0, num_layers=2, noise_type=\"gauss\"):\n",
    "    graph_type, sem_type = \"ER\", \"mlp\"\n",
    "    nonlinear_B_true = utils.simulate_dag(d, s0, graph_type)\n",
    "    nonlinear_dataset = utils.simulate_nonlinear_sem(nonlinear_B_true, n, sem_type, noise_type=noise_type)\n",
    "    # print(f'b_true is {nonlinear_B_true}')\n",
    "\n",
    "    train_samples = int(nonlinear_dataset.shape[0] * 0.8)\n",
    "    test_samples = nonlinear_dataset.shape[0] - train_samples\n",
    "    train_dataset = nonlinear_dataset[:train_samples, :]\n",
    "    test_dataset = nonlinear_dataset[train_samples:, :]\n",
    "\n",
    "    # Nonlinear model\n",
    "    model = flex.MLP(dims=[d, 2, d], num_layers=num_layers, hid_dim=10, activation=\"sigmoid\", bias=True)\n",
    "\n",
    "    # Use AML to solve the constrained problem\n",
    "    cons_solver = flex.AugmentedLagrangian(\n",
    "        num_iter=100000,\n",
    "        num_steps=[1,1],\n",
    "        # l1_coeff=0.01,\n",
    "        # weight_decay=0.01,\n",
    "        rho_init=1e-3,\n",
    "    )\n",
    "\n",
    "    # Use Adam to solve the unconstrained problem\n",
    "    uncons_solver = flex.GradientBasedSolver(\n",
    "        optimizer=torch.optim.RMSprop(model.parameters(), lr=1e-3),\n",
    "    )\n",
    "\n",
    "    # Use MSE loss\n",
    "    loss_fn = flex.MSELoss()\n",
    "\n",
    "    # Use Trace of matrix exponential as DAG function\n",
    "    dag_fn = flex.Grandag_h()\n",
    "\n",
    "    # Learn the DAG\n",
    "    W_est = flex.struct_learn(\n",
    "        dataset=train_dataset,\n",
    "        model=model,\n",
    "        constrained_solver=cons_solver,\n",
    "        unconstrained_solver=uncons_solver,\n",
    "        loss_fn=loss_fn,\n",
    "        dag_fn=dag_fn,\n",
    "        w_threshold=0.0,\n",
    "    )\n",
    "\n",
    "    W_est = postprocess(W_est)\n",
    "\n",
    "    acc = utils.count_accuracy(nonlinear_B_true, W_est != 0)\n",
    "    print(f'Results before CAM pruning: {acc}')\n",
    "\n",
    "    to_keep = (torch.from_numpy(W_est) > 0).type(torch.Tensor)\n",
    "    B_est = model.adjacency * to_keep\n",
    "    # print(f'B_est is {B_est}')\n",
    "\n",
    "    opt = {\n",
    "        'cam_pruning_cutoff': np.logspace(-6, 0, 10),\n",
    "        'exp_path': 'cam_pruning',\n",
    "    }\n",
    "    try:\n",
    "        cam_pruning_cutoff = [float(i) for i in opt['cam_pruning_cutoff']]\n",
    "    except:\n",
    "        cam_pruning_cutoff = [float(opt['cam_pruning_cutoff'])]\n",
    "    for cutoff in cam_pruning_cutoff:\n",
    "        B_est = cam_pruning(B_est, train_dataset, test_dataset, opt, cutoff=cutoff)\n",
    "        # print(f'now B_est is {B_est}')\n",
    "    acc = utils.count_accuracy(nonlinear_B_true, B_est.detach().cpu().numpy() != 0)\n",
    "    print(\"Results: \", acc)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the first value from num_steps for the first 99998 iterations\n",
      "100%|██████████| 100000/100000 [00:45<00:00, 2207.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time: 45.3078351020813\n",
      "Results before CAM pruning: {'fdr': 0.42857142857142855, 'tpr': 0.8, 'fpr': 0.6, 'shd': 3, 'nnz': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the first value from num_steps for the first 99998 iterations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:  {'fdr': 0.3333333333333333, 'tpr': 0.8, 'fpr': 0.4, 'shd': 2, 'nnz': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:28<00:00, 3476.31it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time: 28.776642084121704\n",
      "Results before CAM pruning: {'fdr': 0.5, 'tpr': 0.8, 'fpr': 0.8, 'shd': 5, 'nnz': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the first value from num_steps for the first 99998 iterations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:  {'fdr': 0.0, 'tpr': 0.6, 'fpr': 0.0, 'shd': 2, 'nnz': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:24<00:00, 4104.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time: 24.369171857833862\n",
      "Results before CAM pruning: {'fdr': 0.5, 'tpr': 0.8, 'fpr': 0.8, 'shd': 4, 'nnz': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the first value from num_steps for the first 99998 iterations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:  {'fdr': 0.0, 'tpr': 0.4, 'fpr': 0.0, 'shd': 3, 'nnz': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:49<00:00, 2008.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time: 49.796138048172\n",
      "Results before CAM pruning: {'fdr': 0.5555555555555556, 'tpr': 0.8, 'fpr': 1.0, 'shd': 6, 'nnz': 9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the first value from num_steps for the first 99998 iterations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:  {'fdr': 0.0, 'tpr': 0.4, 'fpr': 0.0, 'shd': 3, 'nnz': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:46<00:00, 2164.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time: 46.204646825790405\n",
      "Results before CAM pruning: {'fdr': 0.5, 'tpr': 0.8, 'fpr': 0.8, 'shd': 4, 'nnz': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the first value from num_steps for the first 99998 iterations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:  {'fdr': 0.25, 'tpr': 0.6, 'fpr': 0.2, 'shd': 2, 'nnz': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:51<00:00, 1950.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time: 51.28387141227722\n",
      "Results before CAM pruning: {'fdr': 0.5555555555555556, 'tpr': 0.8, 'fpr': 1.0, 'shd': 5, 'nnz': 9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the first value from num_steps for the first 99998 iterations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:  {'fdr': 0.42857142857142855, 'tpr': 0.8, 'fpr': 0.6, 'shd': 3, 'nnz': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:02<00:00, 1603.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time: 62.35616064071655\n",
      "Results before CAM pruning: {'fdr': 0.2, 'tpr': 0.8, 'fpr': 0.2, 'shd': 2, 'nnz': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the first value from num_steps for the first 99998 iterations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:  {'fdr': 0.0, 'tpr': 0.8, 'fpr': 0.0, 'shd': 1, 'nnz': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:35<00:00, 2847.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time: 35.13168430328369\n",
      "Results before CAM pruning: {'fdr': 0.4444444444444444, 'tpr': 1.0, 'fpr': 0.8, 'shd': 4, 'nnz': 9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the first value from num_steps for the first 99998 iterations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:  {'fdr': 0.16666666666666666, 'tpr': 1.0, 'fpr': 0.2, 'shd': 1, 'nnz': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:18<00:00, 5477.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time: 18.262706756591797\n",
      "Results before CAM pruning: {'fdr': 0.6, 'tpr': 0.8, 'fpr': 1.2, 'shd': 6, 'nnz': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the first value from num_steps for the first 99998 iterations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:  {'fdr': 0.0, 'tpr': 0.4, 'fpr': 0.0, 'shd': 3, 'nnz': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:32<00:00, 3080.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time: 32.470055103302\n",
      "Results before CAM pruning: {'fdr': 0.5, 'tpr': 1.0, 'fpr': 1.0, 'shd': 5, 'nnz': 10}\n",
      "Results:  {'fdr': 0.0, 'tpr': 1.0, 'fpr': 0.0, 'shd': 0, 'nnz': 5}\n",
      "mean shd: 2.0\n"
     ]
    }
   ],
   "source": [
    "shds = []\n",
    "for i in range(10):\n",
    "    acc = grandag_aug_lagrangian(1000, 5, 5, num_layers=2)\n",
    "    shds.append(acc['shd'])\n",
    "print(f'mean shd: {np.mean(shds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the first value from num_steps for the first 99998 iterations\n",
      "100%|██████████| 100000/100000 [11:11<00:00, 148.89it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time: 671.6974756717682\n",
      "Results before CAM pruning: {'fdr': 0.8, 'tpr': 0.4, 'fpr': 1.6, 'shd': 8, 'sid': 15.0, 'nnz': 10}\n",
      "Results:  {'fdr': 0.6666666666666666, 'tpr': 0.4, 'fpr': 0.8, 'shd': 4, 'sid': 16.0, 'nnz': 6}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fdr': 0.6666666666666666,\n",
       " 'tpr': 0.4,\n",
       " 'fpr': 0.8,\n",
       " 'shd': 4,\n",
       " 'sid': 16.0,\n",
       " 'nnz': 6}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grandag_aug_lagrangian(1000, 5, 5, num_layers=2, noise_type='exp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the first value from num_steps for the first 99998 iterations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time: 976.2653551101685\n",
      "Results before CAM pruning: {'fdr': 0.5714285714285714, 'tpr': 0.6, 'fpr': 0.8, 'shd': 4, 'sid': 7.0, 'nnz': 7}\n",
      "Results:  {'fdr': 0.5, 'tpr': 0.4, 'fpr': 0.4, 'shd': 3, 'sid': 12.0, 'nnz': 4}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fdr': 0.5, 'tpr': 0.4, 'fpr': 0.4, 'shd': 3, 'sid': 12.0, 'nnz': 4}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grandag_aug_lagrangian(1000, 5, 5, num_layers=2, noise_type='gumbel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [04:59<00:00, 334.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time: 299.23108100891113\n",
      "Results before CAM pruning: {'fdr': 0.76, 'tpr': 0.6, 'fpr': 0.5428571428571428, 'shd': 23, 'sid': 13.0, 'nnz': 25}\n",
      "Results:  {'fdr': 0.4444444444444444, 'tpr': 0.5, 'fpr': 0.11428571428571428, 'shd': 9, 'sid': 20.0, 'nnz': 9}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fdr': 0.4444444444444444,\n",
       " 'tpr': 0.5,\n",
       " 'fpr': 0.11428571428571428,\n",
       " 'shd': 9,\n",
       " 'sid': 20.0,\n",
       " 'nnz': 9}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grandag_aug_lagrangian(1000, 10, 10, num_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seren/dagrad/dagrad/flex/modules/constrained_solvers.py:160: UserWarning: Using the first value from num_steps for the first 99998 iterations\n",
      "  self.vwarn(f\"Using the first value from num_steps for the first {missing_steps} iterations\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b_true is [[0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [07:06<00:00, 234.64it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h new is 0.0 and h tol is 1e-08 so ending at 13021th iteration\n",
      "Total Time: 426.18568086624146\n",
      "Results:  {'fdr': 0.8689655172413793, 'tpr': 0.95, 'fpr': 0.7411764705882353, 'shd': 126, 'nnz': 145}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "grandag_aug_lagrangian(1000, 20, 20, num_layers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using flex to implement DAGMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear DAGMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seren/dagrad/dagrad/flex/modules/constrained_solvers.py:49: UserWarning: Using the first value from num_steps for the first 3 iterations\n",
      "  self.vwarn(\n",
      "100%|██████████| 5/5 [00:08<00:00,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time: 8.867684841156006\n",
      "Results:  {'fdr': 0.0, 'tpr': 1.0, 'fpr': 0.0, 'shd': 0, 'nnz': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear model\n",
    "model = flex.LinearModel(d)\n",
    "\n",
    "# Use path following to solve the constrained problem\n",
    "cons_solver = flex.PathFollowing(\n",
    "    num_iter=5,\n",
    "    mu_init=1.0,\n",
    "    mu_scale=0.1,\n",
    "    logdet_coeff=[1.0, .9, .8, .7, .6],\n",
    "    num_steps=[3e4, 6e4],\n",
    "    l1_coeff=0.03,\n",
    ")\n",
    "\n",
    "# use Adam to solve the unconstrained problem\n",
    "uncons_solver = flex.GradientBasedSolver(\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=3e-4, betas=(0.99, 0.999))\n",
    ")\n",
    "\n",
    "# Use MSE loss\n",
    "loss_fn = flex.MSELoss()\n",
    "\n",
    "# Use LogDet as DAG function\n",
    "dag_fn = flex.LogDet()\n",
    "\n",
    "W_est = flex.struct_learn(\n",
    "    dataset=linear_dataset,\n",
    "    model=model,\n",
    "    constrained_solver=cons_solver,\n",
    "    unconstrained_solver=uncons_solver,\n",
    "    loss_fn=loss_fn,\n",
    "    dag_fn=dag_fn,\n",
    "    w_threshold=0.3,\n",
    ")\n",
    "\n",
    "acc = utils.count_accuracy(linear_B_true, W_est != 0)\n",
    "print(\"Results: \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinear DAGMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seren/dagrad/dagrad/flex/modules/constrained_solvers.py:51: UserWarning: Using the first value from num_steps for the first 2 iterations\n",
      "  self.vwarn(\n",
      "100%|██████████| 4/4 [09:40<00:00, 145.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time: 580.489175081253\n",
      "Results:  {'fdr': 0.0, 'tpr': 0.0, 'fpr': 0.0, 'shd': 5, 'nnz': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n, d, s0, graph_type, sem_type = 1000, 5, 5, \"ER\", \"mlp\"\n",
    "nonlinear_B_true = utils.simulate_dag(d, s0, graph_type)\n",
    "nonlinear_dataset = utils.simulate_nonlinear_sem(nonlinear_B_true, n, sem_type)\n",
    "\n",
    "# nonlinear model\n",
    "model = flex.MLP(dims=[d, 2, 5], num_layers=2, hid_dim=10, activation=\"sigmoid\", bias=True)\n",
    "\n",
    "# Use path following to solve the constrained problem\n",
    "cons_solver = flex.PathFollowing(\n",
    "    num_iter=4,\n",
    "    mu_init=0.1,\n",
    "    mu_scale=0.1,\n",
    "    logdet_coeff=1.0,\n",
    "    num_steps=[5e4, 8e4],\n",
    "    weight_decay=0.02,\n",
    "    l1_coeff=0.005,\n",
    ")\n",
    "\n",
    "# use Adam to solve the unconstrained problem\n",
    "uncons_solver = flex.GradientBasedSolver(\n",
    "    # optimizer=torch.optim.Adam(model.parameters(), lr=2e-4, betas=(0.99, 0.999))\n",
    "    optimizer=torch.optim.SGD(model.parameters(), lr=2e-4)\n",
    ")\n",
    "\n",
    "# Use NLL loss\n",
    "loss_fn = flex.NLLLoss()\n",
    "\n",
    "# Use LogDet as DAG function\n",
    "dag_fn = flex.LogDet()\n",
    "\n",
    "# Learn the DAG\n",
    "W_est = flex.struct_learn(\n",
    "    dataset=nonlinear_dataset,\n",
    "    model=model,\n",
    "    constrained_solver=cons_solver,\n",
    "    unconstrained_solver=uncons_solver,\n",
    "    loss_fn=loss_fn,\n",
    "    dag_fn=dag_fn,\n",
    "    w_threshold=0.3,\n",
    ")\n",
    "\n",
    "W_est = postprocess(W_est)\n",
    "acc = utils.count_accuracy(nonlinear_B_true, W_est != 0)\n",
    "print(\"Results: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
