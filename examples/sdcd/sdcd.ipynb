{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Import all the necessary modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from dagrad import dagrad # dagrad is the main class for learning the structure of a DAG\n",
    "from dagrad import generate_linear_data, generate_nonlinear_data, count_accuracy, threshold_till_dag\n",
    "from dagrad.hfunction.h_functions import SCCPowerIteration\n",
    "from dagrad.hfunction.h_functions import h_fn\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(B, graph_thres=0.3):\n",
    "    \"\"\"Post-process estimated solution:\n",
    "        (1) Thresholding.\n",
    "        (2) Remove the edges with smallest absolute weight until a DAG\n",
    "            is obtained.\n",
    "\n",
    "    Args:\n",
    "        B (numpy.ndarray): [d, d] weighted matrix.\n",
    "        graph_thres (float): Threshold for weighted matrix. Default: 0.3.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: [d, d] weighted matrix of DAG.\n",
    "    \"\"\"\n",
    "    B = np.copy(B)\n",
    "    # B[np.abs(B) <= graph_thres] = 0    # Thresholding\n",
    "    B, _ = threshold_till_dag(B)\n",
    "\n",
    "    return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SEM - EV method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdcd_ev(n, d, s0, graph_type, noise_type, error_var, seed=None):\n",
    "    X, W_true, B_true = generate_linear_data(n,d,s0,graph_type,noise_type,error_var,seed)\n",
    "    X = torch.from_numpy(X).float()\n",
    "    model = 'linear' # Define the model\n",
    "    W_sdcd = dagrad(\n",
    "        X,\n",
    "        model = model,\n",
    "        method = 'dagma',\n",
    "        compute_lib='torch',\n",
    "        h_fn='user_h',\n",
    "        general_options={\n",
    "            'user_params': {\n",
    "                'power_grad': SCCPowerIteration(\n",
    "                    torch.zeros(d, d, dtype = torch.float, requires_grad = True, device = 'cpu'),\n",
    "                    d,\n",
    "                )\n",
    "            }\n",
    "        },\n",
    "        # method_options={\n",
    "        #     'mu_factor': 0.9,\n",
    "        # }\n",
    "    ) # Learn the structure of the DAG using SDCD\n",
    "    W_sdcd = postprocess(W_sdcd)\n",
    "    print(f\"Linear Model\")\n",
    "    print(f\"data size: {n}, graph type: {graph_type}, sem type: {noise_type}\")\n",
    "    acc_sdcd = count_accuracy(B_true, W_sdcd != 0) # Measure the accuracy of the learned structure using SDCD\n",
    "    print('Accuracy of SDCD:', acc_sdcd)\n",
    "\n",
    "    return acc_sdcd, W_sdcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Double but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[110], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msdcd_ev\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mER\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgauss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meq\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[109], line 5\u001b[0m, in \u001b[0;36msdcd_ev\u001b[0;34m(n, d, s0, graph_type, noise_type, error_var, seed)\u001b[0m\n\u001b[1;32m      3\u001b[0m X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(X)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# Define the model\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m W_sdcd \u001b[38;5;241m=\u001b[39m \u001b[43mdagrad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdagma\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_lib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtorch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mh_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser_h\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneral_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser_params\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpower_grad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mSCCPowerIteration\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# method_options={\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#     'mu_factor': 0.9,\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# }\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Learn the structure of the DAG using SDCD\u001b[39;00m\n\u001b[1;32m     23\u001b[0m W_sdcd \u001b[38;5;241m=\u001b[39m postprocess(W_sdcd)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLinear Model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/dagrad/dagrad/core.py:250\u001b[0m, in \u001b[0;36mdagrad\u001b[0;34m(X, method, model, loss_fn, h_fn, reg, optimizer, compute_lib, device, general_options, method_options, optimizer_options)\u001b[0m\n\u001b[1;32m    248\u001b[0m                 W_est \u001b[38;5;241m=\u001b[39m parameter_tuning(dag_learning_func \u001b[38;5;241m=\u001b[39m dagma_linear_torch, X \u001b[38;5;241m=\u001b[39m X, model \u001b[38;5;241m=\u001b[39m model, loss_fn \u001b[38;5;241m=\u001b[39m loss_fn, h_fn \u001b[38;5;241m=\u001b[39m h_fn, reg \u001b[38;5;241m=\u001b[39m reg, optimizer \u001b[38;5;241m=\u001b[39m optimizer, options \u001b[38;5;241m=\u001b[39m options)\n\u001b[1;32m    249\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 250\u001b[0m                 W_est \u001b[38;5;241m=\u001b[39m \u001b[43mdagma_linear_torch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_fn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mh_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mreg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnonlinear\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    253\u001b[0m     options[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m device\n",
      "File \u001b[0;32m~/dagrad/dagrad/method/dagma.py:416\u001b[0m, in \u001b[0;36mdagma_linear_torch\u001b[0;34m(X, loss_fn, h_fn, reg, optimizer, T, mu_init, mu_factor, s, warm_iter, main_iter, dtype, exclude_edges, include_edges, verbose, **options)\u001b[0m\n\u001b[1;32m    414\u001b[0m W_est_backup \u001b[38;5;241m=\u001b[39m W_est\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m success \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     W_temp, success \u001b[38;5;241m=\u001b[39m \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW_est\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m                       \u001b[49m\u001b[43moptimizer_options_config\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizer_options_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m                       \u001b[49m\u001b[43moptimizer_options_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizer_options_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m success \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    421\u001b[0m         vprint(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRetrying with larger s\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/dagrad/dagrad/method/dagma.py:375\u001b[0m, in \u001b[0;36mdagma_linear_torch.<locals>.minimize\u001b[0;34m(W_est, optimizer_options_config, optimizer_options_settings, mu, s)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;66;03m# M = torch.linalg.inv(s * Id - W_est @ W_est) + 1e-6\u001b[39;00m\n\u001b[1;32m    374\u001b[0m     general_options[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m s\n\u001b[0;32m--> 375\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[43m_h\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW_est\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgeneral_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# while torch.any(M <0):\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m h\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/dagrad/dagrad/hfunction/h_functions.py:139\u001b[0m, in \u001b[0;36mh_fn.user_h\u001b[0;34m(W, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m user_params \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_params\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    138\u001b[0m power_grad: SCCPowerIteration \u001b[38;5;241m=\u001b[39m user_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpower_grad\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 139\u001b[0m grad, A \u001b[38;5;241m=\u001b[39m \u001b[43mpower_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_gradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m h_val \u001b[38;5;241m=\u001b[39m (grad\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m*\u001b[39m A)\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m h_val\n",
      "File \u001b[0;32m~/dagrad/dagrad/hfunction/h_functions.py:83\u001b[0m, in \u001b[0;36mSCCPowerIteration.compute_gradient\u001b[0;34m(self, adj_mtx)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_updates \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_scc_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_scc(adj_mtx)\n\u001b[0;32m---> 83\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_eigenvectors\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj_mtx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# matrix = self.power_iteration(4)\u001b[39;00m\n\u001b[1;32m     86\u001b[0m matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize_eigenvectors(adj_mtx)\n",
      "File \u001b[0;32m~/dagrad/dagrad/hfunction/h_functions.py:40\u001b[0m, in \u001b[0;36mSCCPowerIteration.initialize_eigenvectors\u001b[0;34m(self, adj_mtx)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv \u001b[38;5;241m=\u001b[39m normalize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvt \u001b[38;5;241m=\u001b[39m normalize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvt)\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpower_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj_mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dagrad/dagrad/hfunction/h_functions.py:73\u001b[0m, in \u001b[0;36mSCCPowerIteration.power_iteration\u001b[0;34m(self, adj_mtx, n_iter)\u001b[0m\n\u001b[1;32m     71\u001b[0m vt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvt[scc]\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iter):\n\u001b[0;32m---> 73\u001b[0m     v \u001b[38;5;241m=\u001b[39m normalize(\u001b[43msub_matrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-6\u001b[39m \u001b[38;5;241m*\u001b[39m v\u001b[38;5;241m.\u001b[39msum())\n\u001b[1;32m     74\u001b[0m     vt \u001b[38;5;241m=\u001b[39m normalize(sub_matrix\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mmv(vt) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-6\u001b[39m \u001b[38;5;241m*\u001b[39m vt\u001b[38;5;241m.\u001b[39msum())\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv[scc] \u001b[38;5;241m=\u001b[39m v\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Double but found Float"
     ]
    }
   ],
   "source": [
    "sdcd_ev(1000, 5, 5, 'ER', 'gauss', 'eq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model\n",
      "data size: 1000, graph type: ER, sem type: gauss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(77337) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SDCD: {'fdr': 0.2, 'tpr': 0.8, 'fpr': 0.05714285714285714, 'shd': 4, 'sid': 3.0, 'nnz': 10}\n",
      "W_pred: [[ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 3.45581977  0.          0.          0.          0.          0.\n",
      "  -1.74145973  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.         -0.63760318  0.\n",
      "   0.          0.          0.52717284  0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [-0.54047649  0.         -1.55390686  0.          0.          0.\n",
      "   0.51440096  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.93850408  0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 1.1616069   0.          0.          0.          0.          0.\n",
      "  -1.42703527  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]]\n",
      "sdcd h: 50.0\n",
      "logdet h: 0.5753641449035619\n",
      "logdet_abs h: 1.3862943611198908\n",
      "h_exp_sq: 0.5680508333754872\n"
     ]
    }
   ],
   "source": [
    "_, W_pred = sdcd_ev(1000, 10, 10, 'ER', 'gauss', 'eq')#, seed=2)\n",
    "print(f'W_pred: {W_pred}')\n",
    "W_pred[0, 0] = 0.5\n",
    "W_pred[1, 1] = 0.5\n",
    "d = 10\n",
    "sdcd_h = h_fn.user_h(torch.from_numpy(W_pred).double(), user_params={\n",
    "                'power_grad': SCCPowerIteration(\n",
    "                    torch.zeros(d, d, dtype = torch.double, requires_grad = True, device = 'cpu'),\n",
    "                    d,\n",
    "                )\n",
    "            }\n",
    ")\n",
    "print(f'sdcd h: {sdcd_h}')\n",
    "logdet_h = h_fn.h_logdet_sq(torch.from_numpy(W_pred).double())\n",
    "print(f'logdet h: {logdet_h}')\n",
    "logdet_abs_h = h_fn.h_logdet_abs(torch.from_numpy(W_pred).double())\n",
    "print(f'logdet_abs h: {logdet_abs_h}')\n",
    "h_exp_sq = h_fn.h_exp_sq(torch.from_numpy(W_pred).double())\n",
    "print(f'h_exp_sq: {h_exp_sq}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model\n",
      "data size: 1000, graph type: ER, sem type: gauss\n",
      "Accuracy of SDCD: {'fdr': 0.0, 'tpr': 0.66, 'fpr': 0.0, 'shd': 17, 'nnz': 33}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fdr': 0.0, 'tpr': 0.66, 'fpr': 0.0, 'shd': 17, 'nnz': 33}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdcd_ev(1000, 100, 50, 'ER', 'gauss', 'eq', seed=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model\n",
      "data size: 1000, graph type: SF, nodes: 50, edges: 100, sem type: gauss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(55874) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Golem: {'fdr': 0.09523809523809523, 'tpr': 0.979381443298969, 'fpr': 0.008865248226950355, 'shd': 10, 'sid': 19.0, 'nnz': 105}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fdr': 0.09523809523809523,\n",
       " 'tpr': 0.979381443298969,\n",
       " 'fpr': 0.008865248226950355,\n",
       " 'shd': 10,\n",
       " 'sid': 19.0,\n",
       " 'nnz': 105}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "golem_ev(1000, 50, 100, 'SF', 'gauss', 'eq', seed=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model\n",
      "data size: 1000, graph type: ER, sem type: gauss\n",
      "Accuracy of Dagma: {'fdr': 0.0, 'tpr': 1.0, 'fpr': 0.0, 'shd': 0, 'sid': 0.0, 'nnz': 50}\n"
     ]
    }
   ],
   "source": [
    "# ER1 graph with 100 nodes, as in https://arxiv.org/pdf/2006.10201 5.1\n",
    "n, d, s0, graph_type, noise_type = 1000, 100, 50, 'ER', 'gauss' # Define the parameters of the data\n",
    "X, W_true, B_true = generate_linear_data(n,d,s0,graph_type,noise_type, error_var='eq',seed  =2) # Generate the data\n",
    "X = torch.from_numpy(X).float()\n",
    "model = 'linear' # Define the model\n",
    "W_dagma = dagrad(\n",
    "    X,\n",
    "    model = model,\n",
    "    method = 'dagma',\n",
    "    compute_lib='torch',\n",
    ") # Learn the structure of the DAG using Dagma\n",
    "print(f\"Linear Model\")\n",
    "print(f\"data size: {n}, graph type: {graph_type}, sem type: {noise_type}\")\n",
    "\n",
    "acc_dagma = count_accuracy(B_true, W_dagma != 0) # Measure the accuracy of the learned structure using Dagma\n",
    "print('Accuracy of Dagma:', acc_dagma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model\n",
      "data size: 1000, graph type: ER, nodes: 100, edges: 200, sem type: gauss\n",
      "Accuracy of Golem: {'fdr': 0.009950248756218905, 'tpr': 0.995, 'fpr': 0.0004210526315789474, 'shd': 2, 'sid': 25.0, 'nnz': 201}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fdr': 0.009950248756218905,\n",
       " 'tpr': 0.995,\n",
       " 'fpr': 0.0004210526315789474,\n",
       " 'shd': 2,\n",
       " 'sid': 25.0,\n",
       " 'nnz': 201}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "golem_ev(1000, 100, 200, 'ER', 'gauss', 'eq', seed=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model\n",
      "data size: 1000, graph type: ER, sem type: gauss\n",
      "Accuracy of Dagma: {'fdr': 0.0, 'tpr': 0.985, 'fpr': 0.0, 'shd': 3, 'sid': 134.0, 'nnz': 197}\n"
     ]
    }
   ],
   "source": [
    "# ER4 graph with 100 nodes, as in https://arxiv.org/pdf/2006.10201 5.1\n",
    "n, d, s0, graph_type, noise_type = 1000, 100, 200, 'ER', 'gauss' # Define the parameters of the data\n",
    "X, W_true, B_true = generate_linear_data(n,d,s0,graph_type,noise_type,error_var='eq',seed  =2) # Generate the data\n",
    "X = torch.from_numpy(X).float()\n",
    "model = 'linear' # Define the model\n",
    "W_dagma = dagrad(\n",
    "    X,\n",
    "    model = model,\n",
    "    method = 'dagma',\n",
    "    compute_lib='torch',\n",
    ") # Learn the structure of the DAG using Dagma\n",
    "print(f\"Linear Model\")\n",
    "print(f\"data size: {n}, graph type: {graph_type}, sem type: {noise_type}\")\n",
    "\n",
    "acc_dagma = count_accuracy(B_true, W_dagma != 0) # Measure the accuracy of the learned structure using Dagma\n",
    "print('Accuracy of Dagma:', acc_dagma)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
