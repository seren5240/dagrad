{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU automatically detected. Setting SETTINGS.GPU to 0, and SETTINGS.NJOBS to cpu_count.\n"
     ]
    }
   ],
   "source": [
    "# Import all the necessary modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from dagrad import dagrad # dagrad is the main class for learning the structure of a DAG\n",
    "from dagrad import generate_linear_data, generate_nonlinear_data, count_accuracy, threshold_till_dag\n",
    "from dagrad.hfunction.h_functions import SCCPowerIteration\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(B, graph_thres=0.3):\n",
    "    \"\"\"Post-process estimated solution:\n",
    "        (1) Thresholding.\n",
    "        (2) Remove the edges with smallest absolute weight until a DAG\n",
    "            is obtained.\n",
    "\n",
    "    Args:\n",
    "        B (numpy.ndarray): [d, d] weighted matrix.\n",
    "        graph_thres (float): Threshold for weighted matrix. Default: 0.3.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: [d, d] weighted matrix of DAG.\n",
    "    \"\"\"\n",
    "    B = np.copy(B)\n",
    "    B[np.abs(B) <= graph_thres] = 0    # Thresholding\n",
    "    B, _ = threshold_till_dag(B)\n",
    "\n",
    "    return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SEM - EV method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdcd_ev(n, d, s0, graph_type, noise_type, error_var, seed=None):\n",
    "    X, W_true, B_true = generate_linear_data(n,d,s0,graph_type,noise_type,error_var,seed)\n",
    "    X = torch.from_numpy(X).float()\n",
    "    model = 'linear' # Define the model\n",
    "    W_sdcd = dagrad(\n",
    "        X,\n",
    "        model = model,\n",
    "        method = 'dagma',\n",
    "        compute_lib='torch',\n",
    "        h_fn='user_h',\n",
    "        general_options={\n",
    "            'user_params': {\n",
    "                'is_prescreen': False,\n",
    "                'power_grad': SCCPowerIteration(\n",
    "                    torch.zeros(d, d, dtype = torch.double, requires_grad = True, device = 'cpu'),\n",
    "                    d,\n",
    "                )\n",
    "            }\n",
    "        },\n",
    "        method_options={\n",
    "            'mu_factor': 0.9,\n",
    "        }\n",
    "    ) # Learn the structure of the DAG using SDCD\n",
    "    W_sdcd = postprocess(W_sdcd)\n",
    "    print(f\"Linear Model\")\n",
    "    print(f\"data size: {n}, graph type: {graph_type}, sem type: {noise_type}\")\n",
    "    acc_sdcd = count_accuracy(B_true, W_sdcd != 0) # Measure the accuracy of the learned structure using SDCD\n",
    "    print('Accuracy of SDCD:', acc_sdcd)\n",
    "\n",
    "    return acc_sdcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model\n",
      "data size: 1000, graph type: ER, sem type: gauss\n",
      "Accuracy of SDCD: {'fdr': 0.0, 'tpr': 1.0, 'fpr': 0.0, 'shd': 0, 'nnz': 5}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fdr': 0.0, 'tpr': 1.0, 'fpr': 0.0, 'shd': 0, 'nnz': 5}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdcd_ev(1000, 5, 5, 'ER', 'gauss', 'eq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model\n",
      "data size: 1000, graph type: ER, sem type: gauss\n",
      "Accuracy of SDCD: {'fdr': 0.1111111111111111, 'tpr': 0.8, 'fpr': 0.02857142857142857, 'shd': 3, 'nnz': 9}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fdr': 0.1111111111111111,\n",
       " 'tpr': 0.8,\n",
       " 'fpr': 0.02857142857142857,\n",
       " 'shd': 3,\n",
       " 'nnz': 9}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdcd_ev(1000, 10, 10, 'ER', 'gauss', 'eq')#, seed=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model\n",
      "data size: 1000, graph type: ER, sem type: gauss\n",
      "Accuracy of SDCD: {'fdr': 0.0, 'tpr': 0.66, 'fpr': 0.0, 'shd': 17, 'nnz': 33}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fdr': 0.0, 'tpr': 0.66, 'fpr': 0.0, 'shd': 17, 'nnz': 33}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdcd_ev(1000, 100, 50, 'ER', 'gauss', 'eq', seed=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model\n",
      "data size: 1000, graph type: SF, nodes: 50, edges: 100, sem type: gauss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(55874) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Golem: {'fdr': 0.09523809523809523, 'tpr': 0.979381443298969, 'fpr': 0.008865248226950355, 'shd': 10, 'sid': 19.0, 'nnz': 105}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fdr': 0.09523809523809523,\n",
       " 'tpr': 0.979381443298969,\n",
       " 'fpr': 0.008865248226950355,\n",
       " 'shd': 10,\n",
       " 'sid': 19.0,\n",
       " 'nnz': 105}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "golem_ev(1000, 50, 100, 'SF', 'gauss', 'eq', seed=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model\n",
      "data size: 1000, graph type: ER, sem type: gauss\n",
      "Accuracy of Dagma: {'fdr': 0.0, 'tpr': 1.0, 'fpr': 0.0, 'shd': 0, 'sid': 0.0, 'nnz': 50}\n"
     ]
    }
   ],
   "source": [
    "# ER1 graph with 100 nodes, as in https://arxiv.org/pdf/2006.10201 5.1\n",
    "n, d, s0, graph_type, noise_type = 1000, 100, 50, 'ER', 'gauss' # Define the parameters of the data\n",
    "X, W_true, B_true = generate_linear_data(n,d,s0,graph_type,noise_type, error_var='eq',seed  =2) # Generate the data\n",
    "X = torch.from_numpy(X).float()\n",
    "model = 'linear' # Define the model\n",
    "W_dagma = dagrad(\n",
    "    X,\n",
    "    model = model,\n",
    "    method = 'dagma',\n",
    "    compute_lib='torch',\n",
    ") # Learn the structure of the DAG using Dagma\n",
    "print(f\"Linear Model\")\n",
    "print(f\"data size: {n}, graph type: {graph_type}, sem type: {noise_type}\")\n",
    "\n",
    "acc_dagma = count_accuracy(B_true, W_dagma != 0) # Measure the accuracy of the learned structure using Dagma\n",
    "print('Accuracy of Dagma:', acc_dagma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model\n",
      "data size: 1000, graph type: ER, nodes: 100, edges: 200, sem type: gauss\n",
      "Accuracy of Golem: {'fdr': 0.009950248756218905, 'tpr': 0.995, 'fpr': 0.0004210526315789474, 'shd': 2, 'sid': 25.0, 'nnz': 201}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fdr': 0.009950248756218905,\n",
       " 'tpr': 0.995,\n",
       " 'fpr': 0.0004210526315789474,\n",
       " 'shd': 2,\n",
       " 'sid': 25.0,\n",
       " 'nnz': 201}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "golem_ev(1000, 100, 200, 'ER', 'gauss', 'eq', seed=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model\n",
      "data size: 1000, graph type: ER, sem type: gauss\n",
      "Accuracy of Dagma: {'fdr': 0.0, 'tpr': 0.985, 'fpr': 0.0, 'shd': 3, 'sid': 134.0, 'nnz': 197}\n"
     ]
    }
   ],
   "source": [
    "# ER4 graph with 100 nodes, as in https://arxiv.org/pdf/2006.10201 5.1\n",
    "n, d, s0, graph_type, noise_type = 1000, 100, 200, 'ER', 'gauss' # Define the parameters of the data\n",
    "X, W_true, B_true = generate_linear_data(n,d,s0,graph_type,noise_type,error_var='eq',seed  =2) # Generate the data\n",
    "X = torch.from_numpy(X).float()\n",
    "model = 'linear' # Define the model\n",
    "W_dagma = dagrad(\n",
    "    X,\n",
    "    model = model,\n",
    "    method = 'dagma',\n",
    "    compute_lib='torch',\n",
    ") # Learn the structure of the DAG using Dagma\n",
    "print(f\"Linear Model\")\n",
    "print(f\"data size: {n}, graph type: {graph_type}, sem type: {noise_type}\")\n",
    "\n",
    "acc_dagma = count_accuracy(B_true, W_dagma != 0) # Measure the accuracy of the learned structure using Dagma\n",
    "print('Accuracy of Dagma:', acc_dagma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SEM with EV noise - Two-stage method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdcd_nv(n, d, s0, graph_type, noise_type, error_var, seed=None):\n",
    "    X, W_true, B_true = generate_nonlinear_data(n,d,s0,graph_type,noise_type=noise_type,error_var=error_var,seed=seed)\n",
    "    X = torch.from_numpy(X).float()\n",
    "    model = 'nonlinear' # Define the model\n",
    "    W_sdcd = dagrad(\n",
    "        X,\n",
    "        model = model,\n",
    "        method = 'dagma',\n",
    "        compute_lib='torch',\n",
    "        h_fn='user_h',\n",
    "        general_options={\n",
    "            'user_params': {\n",
    "                'is_prescreen': False,\n",
    "                'power_grad': SCCPowerIteration(\n",
    "                    torch.zeros(d, d, dtype = torch.double, requires_grad = True, device = 'cpu'),\n",
    "                    d,\n",
    "                )\n",
    "            }\n",
    "        },\n",
    "        method_options={\n",
    "            'mu_factor': 1.0,\n",
    "        }\n",
    "    ) # Learn the structure of the DAG using SDCD\n",
    "    W_sdcd = postprocess(W_sdcd)\n",
    "    print(f\"Nonlinear Model\")\n",
    "    print(f\"data size: {n}, graph type: {graph_type}, sem type: {noise_type}\")\n",
    "    acc_sdcd = count_accuracy(B_true, W_sdcd != 0) # Measure the accuracy of the learned structure using SDCD\n",
    "    print('Accuracy of SDCD:', acc_sdcd)\n",
    "\n",
    "    return acc_sdcd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msdcd_nv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mER\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgauss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meq\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[42], line 5\u001b[0m, in \u001b[0;36msdcd_nv\u001b[0;34m(n, d, s0, graph_type, noise_type, error_var, seed)\u001b[0m\n\u001b[1;32m      3\u001b[0m X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(X)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnonlinear\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# Define the model\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m W_sdcd \u001b[38;5;241m=\u001b[39m \u001b[43mdagrad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdagma\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_lib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtorch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mh_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser_h\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneral_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser_params\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mis_prescreen\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpower_grad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mSCCPowerIteration\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdouble\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmu_factor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Learn the structure of the DAG using SDCD\u001b[39;00m\n\u001b[1;32m     24\u001b[0m W_sdcd \u001b[38;5;241m=\u001b[39m postprocess(W_sdcd)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNonlinear Model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/dagrad/dagrad/core.py:301\u001b[0m, in \u001b[0;36mdagrad\u001b[0;34m(X, method, model, loss_fn, h_fn, reg, optimizer, compute_lib, device, general_options, method_options, optimizer_options)\u001b[0m\n\u001b[1;32m    287\u001b[0m         W_est \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X \u001b[38;5;241m=\u001b[39m X, \n\u001b[1;32m    288\u001b[0m                           lambda1 \u001b[38;5;241m=\u001b[39m options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlambda1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0.02\u001b[39m), \n\u001b[1;32m    289\u001b[0m                           lambda2 \u001b[38;5;241m=\u001b[39m options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlambda2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0.005\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    298\u001b[0m                           checkpoint\u001b[38;5;241m=\u001b[39m options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheck_iterate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1000\u001b[39m),\n\u001b[1;32m    299\u001b[0m             )\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 301\u001b[0m         W_est \u001b[38;5;241m=\u001b[39m \u001b[43mdagma_nonlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_fn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mh_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mreg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtopo\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    304\u001b[0m     W_est \u001b[38;5;241m=\u001b[39m topo_nonlinear(X \u001b[38;5;241m=\u001b[39m X, loss_fn \u001b[38;5;241m=\u001b[39m loss_fn, h_fn \u001b[38;5;241m=\u001b[39m h_fn, \n\u001b[1;32m    305\u001b[0m                             reg \u001b[38;5;241m=\u001b[39m reg, optimizer \u001b[38;5;241m=\u001b[39m optimizer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/dagrad/dagrad/method/dagma.py:598\u001b[0m, in \u001b[0;36mdagma_nonlinear\u001b[0;34m(X, loss_fn, h_fn, reg, optimizer, activation, dims, T, mu_init, mu_factor, s, warm_iter, main_iter, dtype, verbose, bias, **options)\u001b[0m\n\u001b[1;32m    595\u001b[0m model_copy \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(model)\n\u001b[1;32m    597\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m success \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m--> 598\u001b[0m     success \u001b[38;5;241m=\u001b[39m \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m                       \u001b[49m\u001b[43moptimizer_options_config\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizer_options_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m                       \u001b[49m\u001b[43moptimizer_options_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizer_options_settings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m                       \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ms_cur\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m success \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    604\u001b[0m         model\u001b[38;5;241m.\u001b[39mload_state_dict(model_copy\u001b[38;5;241m.\u001b[39mstate_dict()\u001b[38;5;241m.\u001b[39mcopy())\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/dagrad/dagrad/method/dagma.py:573\u001b[0m, in \u001b[0;36mdagma_nonlinear.<locals>.minimize\u001b[0;34m(model, optimizer_options_config, optimizer_options_settings, mu, s)\u001b[0m\n\u001b[1;32m    571\u001b[0m l2_reg \u001b[38;5;241m=\u001b[39m lambda2 \u001b[38;5;241m*\u001b[39m model\u001b[38;5;241m.\u001b[39ml2_reg()\n\u001b[1;32m    572\u001b[0m obj \u001b[38;5;241m=\u001b[39m mu \u001b[38;5;241m*\u001b[39m (score \u001b[38;5;241m+\u001b[39m reg \u001b[38;5;241m+\u001b[39m l2_reg) \u001b[38;5;241m+\u001b[39m h_val\n\u001b[0;32m--> 573\u001b[0m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    574\u001b[0m opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lr_decay \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m%\u001b[39m check_iterate \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dagrad/dagrad/utils/NNstructure.py:159\u001b[0m, in \u001b[0;36mDagmaMLP.make_hook_function.<locals>.hook_function\u001b[0;34m(grad)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_hook_function\u001b[39m(column_idx):\n\u001b[0;32m--> 159\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhook_function\u001b[39m(grad):\n\u001b[1;32m    160\u001b[0m         grad_clone \u001b[38;5;241m=\u001b[39m grad\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m    161\u001b[0m         grad_clone[:, column_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m  \u001b[38;5;66;03m# Zero out the specific column's gradient\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sdcd_nv(1000, 100, 200, 'ER', 'gauss', 'eq', seed=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model\n",
      "data size: 1000, graph type: ER, nodes: 100, edges: 50, sem type: exp\n",
      "Accuracy of Golem after EV stage: {'fdr': 0.09259259259259259, 'tpr': 0.98, 'fpr': 0.0010204081632653062, 'shd': 5, 'sid': 2.0, 'nnz': 54}\n",
      "Accuracy of Golem after NV stage: {'fdr': 0.14035087719298245, 'tpr': 0.98, 'fpr': 0.0016326530612244899, 'shd': 8, 'sid': 2.0, 'nnz': 57}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fdr': 0.14035087719298245,\n",
       " 'tpr': 0.98,\n",
       " 'fpr': 0.0016326530612244899,\n",
       " 'shd': 8,\n",
       " 'sid': 2.0,\n",
       " 'nnz': 57}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "golem_nv(1000, 100, 50, 'ER', 'exp', 'eq', seed=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model\n",
      "data size: 1000, graph type: ER, nodes: 100, edges: 50, sem type: gauss\n",
      "Accuracy of Golem after EV stage: {'fdr': 0.0, 'tpr': 1.0, 'fpr': 0.0, 'shd': 0, 'sid': 0.0, 'nnz': 50}\n",
      "Accuracy of Golem after NV stage: {'fdr': 0.0, 'tpr': 1.0, 'fpr': 0.0, 'shd': 0, 'sid': 0.0, 'nnz': 50}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fdr': 0.0, 'tpr': 1.0, 'fpr': 0.0, 'shd': 0, 'sid': 0.0, 'nnz': 50}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "golem_nv(1000, 100, 50, 'ER', 'gauss', 'eq', seed=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model\n",
      "data size: 1000, graph type: ER, nodes: 10, edges: 40, sem type: gauss\n",
      "Accuracy of Golem after EV stage: {'fdr': 0.0, 'tpr': 1.0, 'fpr': 0.0, 'shd': 0, 'sid': 0.0, 'nnz': 40}\n",
      "Accuracy of Golem after NV stage: {'fdr': 0.0, 'tpr': 1.0, 'fpr': 0.0, 'shd': 0, 'sid': 0.0, 'nnz': 40}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fdr': 0.0, 'tpr': 1.0, 'fpr': 0.0, 'shd': 0, 'sid': 0.0, 'nnz': 40}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "golem_nv(1000, 10, 40, 'ER', 'gauss', 'eq', seed=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model\n",
      "data size: 1000, graph type: ER, nodes: 100, edges: 200, sem type: gauss\n",
      "Accuracy of Golem after EV stage: {'fdr': 0.009950248756218905, 'tpr': 0.995, 'fpr': 0.0004210526315789474, 'shd': 2, 'sid': 25.0, 'nnz': 201}\n",
      "Accuracy of Golem after NV stage: {'fdr': 0.009950248756218905, 'tpr': 0.995, 'fpr': 0.0004210526315789474, 'shd': 2, 'sid': 25.0, 'nnz': 201}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fdr': 0.009950248756218905,\n",
       " 'tpr': 0.995,\n",
       " 'fpr': 0.0004210526315789474,\n",
       " 'shd': 2,\n",
       " 'sid': 25.0,\n",
       " 'nnz': 201}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "golem_nv(1000, 100, 200, 'ER', 'gauss', 'eq', seed=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SEM with NV noise - Two-stage method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model\n",
      "data size: 1000, graph type: ER, nodes: 100, edges: 50, sem type: gumbel\n",
      "Accuracy of Golem after EV stage: {'fdr': 0.7972972972972973, 'tpr': 0.9, 'fpr': 0.03612244897959184, 'shd': 180, 'sid': 16.0, 'nnz': 222}\n",
      "Accuracy of Golem after NV stage: {'fdr': 0.17543859649122806, 'tpr': 0.94, 'fpr': 0.0020408163265306124, 'shd': 10, 'sid': 16.0, 'nnz': 57}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fdr': 0.17543859649122806,\n",
       " 'tpr': 0.94,\n",
       " 'fpr': 0.0020408163265306124,\n",
       " 'shd': 10,\n",
       " 'sid': 16.0,\n",
       " 'nnz': 57}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "golem_nv(1000, 100, 50, 'ER', 'gumbel', 'random', seed=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model\n",
      "data size: 1000, graph type: ER, nodes: 20, edges: 10, sem type: gauss\n",
      "Accuracy of Golem after EV stage: {'fdr': 0.7674418604651163, 'tpr': 1.0, 'fpr': 0.18333333333333332, 'shd': 33, 'sid': 0.0, 'nnz': 43}\n",
      "Accuracy of Golem after NV stage: {'fdr': 0.0, 'tpr': 1.0, 'fpr': 0.0, 'shd': 0, 'sid': 0.0, 'nnz': 10}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fdr': 0.0, 'tpr': 1.0, 'fpr': 0.0, 'shd': 0, 'sid': 0.0, 'nnz': 10}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "golem_nv(1000, 20, 10, 'ER', 'gauss', 'random', seed=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
